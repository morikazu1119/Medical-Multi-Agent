services:
  # 事前にtorchをインストールしたベースイメージを作成
  # 各コンテナのtorchのインストール時間を短縮
  torch-cuda:
    build:
      context: ./docker/base/torch-cuda
      dockerfile: Dockerfile
    container_name: torch_cuda
    image: torch-cuda

  sample:
    build:
      context: ./src/mcp_servers/sample
      dockerfile: Dockerfile
      args:
        HOST: 0.0.0.0
        PORT: 10001
    container_name: sample_server
    ports:
      - "10001:10001"
    restart: unless-stopped

  gemini:
    build:
      context: ./src/mcp_servers/gemini
      dockerfile: Dockerfile
      args:
        HOST: 0.0.0.0
        PORT: 10002
    container_name: gemini_server
    volumes:
      - ./key.env:/app/key.env
      - ./src/config/config.yaml:/app/config.yaml
    ports:
      - "10002:10002"
    restart: unless-stopped

  medgemma-bnb:
    depends_on:
      - torch-cuda
    build:
      context: ./src/mcp_servers/medgemma-bnb
      dockerfile: Dockerfile
      args:
        HOST: 0.0.0.0
        PORT: 10003
    container_name: medgemma-bnb_server
    ports:
      - "10003:10003"
    restart: unless-stopped
    volumes:
      - slum-volume:/mnt/slum
      - ./src/config/config.yaml:/app/config.yaml
    gpus:
      - count: all
      - devices: all

  lingshu-bnb:
    depends_on:
      - torch-cuda
    build:
      context: ./src/mcp_servers/lingshu-bnb
      dockerfile: Dockerfile
      args:
        HOST: 0.0.0.0
        PORT: 10004
    container_name: lingshu-bnb_server
    ports:
      - "10004:10004"
    restart: unless-stopped
    volumes:
      - slum-volume:/mnt/slum
      - ./src/config/config.yaml:/app/config.yaml
    gpus:
      - count: all
      - devices: all

  blip-mediphi-bnb:
    depends_on:
      - torch-cuda
    build:
      context: ./src/mcp_servers/blip-mediphi-bnb
      dockerfile: Dockerfile
      args:
        HOST: 0.0.0.0
        PORT: 10005
    container_name: blip-mediphi-bnb_server
    ports:
      - "10005:10005"
    restart: unless-stopped
    volumes:
      - slum-volume:/mnt/slum
      - ./src/config/config.yaml:/app/config.yaml
    gpus:
      - count: all
      - devices: all

volumes:
  slum-volume:
    external: true
